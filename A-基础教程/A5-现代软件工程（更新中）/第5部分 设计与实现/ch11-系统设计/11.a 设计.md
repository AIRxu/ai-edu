# 设计

## 10.3.1 应用场景

我们仍然使用 10.2.2 节中的项目的故事为例，来说明一个完整分析、设计过程。为了方便阅读，我们再重复一下这个故事场景。

木头参与的一个真实项目，虽然不怎么大，但是麻雀虽小五脏俱全，服务于客户的系统，无论规模如何，都要全力以赴，谨慎对待。

- 某基金客户想使用热门的深度学习来预测 A 股股票行情走向，所以找到了 MSRA 请求合作。客户将会在每周末上传上一周的股票交易数据，在微软 Azure 上完成存储、处理、预测、输出等一系列过程，然后从 Azure 上下载预测结果。

- 我软的研究员们深入研究了几个月，他们根据股票交易历史数据，在 Azure 上训练了一系列基于神经网络的深度学习模型，存入模型库中。

- 我软的工程师们，会监控客户的上传数据动作，一旦上传结束后，立刻在 Azure 上启动预测流程，调用研究员的模型库，根据最新交易结果进行预测，得到预测结果后，通知客户下载。

## 10.3.2 需求分析初步

我们根据上面的需求描述，把每个参与者（用户、研究员、工程师）的数据流图单独画出来，这样可以避免一开始就陷入复杂的逻辑纠缠中。

图 10.3.1 的独立数据流图描述了需求分析的结果。

<div align="center">
<img src="Images/Slide3.JPG"/>
图 10.3.1 - 独立数据流图
</div>

### 用户数据流图

流程：

1. 用户上传数据到云端的数据存储上；
2. 用户得到通知后，下载预测结果文件。

对用户来说比较简单，就是两个动作：上传、下载，后面的一切流程都是透明的。所以，我们需要设计“上传”和“下载”的实现。

### 研究员数据流图

流程：

1. 研究员在自己的计算机上设计模型，并提交训练代码到云端存储；
2. 云端有一个代码存储库（蓝色部分），包括模型、代码、初始参数等；
3. 研究员登录到云端服务器，启动训练过程；
4. 在训练开始时，需要读取存储在云端的股票历史数据（浅绿色部分）；
5. 训练结束后，把成熟的模型存放到模型库（黄色部分），供预测使用。

对研究员来说，“提交训练代码”和“训练”是两个主要动作，代码可以在本地计算机上完成实现，与 Azure 交互的是“提交”动作，还要考虑“训练”部署在什么设备上运行，其它的一些辅助存储需要 Azure 上的哪种存储设备。

### 工程师数据流图

流程：

1. 开发完毕后，提交预测代码到云端部署（蓝色部分）；
2. 启动预测过程；
3. 在预测开始前，要读取股票历史数据和最新上传的数据（浅绿色部分），还要从模型库（黄色部分）中读取最新模型；
4. 预测完毕后，输出结果文件（绿色部分），并通知用户去下载。

对于工程师来说，“提交预测代码”和“预测”是两个主要动作，代码可以在本地计算机上完成实现，与 Azure 交互的是“提交”动作，还要考虑“预测”部署在什么设备上运行，其它的一些辅助存储需要 Azure 上的哪种存储设备。

## 10.3.3 集成分析

下面我们需要把三个独立的数据流图合并成一个完整的数据流图，来发现需要改进的地方。如图 10.3.2 所示。

<div align="center">
<img src="Images/Slide4.JPG"/>
图 10.3.2 - 整体数据流图
</div>

合并的过程很简单，把图 10.3.1 中重复（具有相同名字并且相同颜色）的单元删掉，但是保留连接线。比如“股票数据（存储）”单元一共有三个，删掉右侧的两个，然后把“上传文件”连接到左侧的“股票数据（存储）”上，再把“预测”连接到左侧的“股票数据（存储）”上，箭头方向保持不变。

如此重复，去掉所有重名重色的单元后，再调整各个单元的位置，尽量让连接线没有交叉，就变成了图 10.3.2 的样子。当然，由于这是一个拓扑图，所以可能画法不止一种。

与图 10.3.1 不同的是，这里多了一个深色的矩形区域“Azure”，表明在我们的设计中，矩形区域内的元素，包括数据、行为、流程，都应该使用 Azure 提供的技术。

得到图 10.3.2 后，就可以进行下一步的设计工作了。注意，在依赖数据流图把需求分析变成系统设计的过程中，有一些“潜规则”：

1. “参与者”到“加工逻辑”之间的连线（有方向），表示有交互式用户界面，或者可执行程序（也可以看作是界面的一种）。
2. 两个“加工逻辑”之间的连线，表示前者调用/通知后者，也可能有一个总控程序，按顺序调用二者。
3. “加工逻辑”到“数据存储”的连线（有方向），表示调用“写入”功能。
4. “数据存储”到“加工逻辑”的连线（有方向），表示调用“读出”功能，但是此时的“加工逻辑”不能凭空运行，需要有调用者，见2。
5. 
6. 


## 10.3.4 设计触发机制

需求要求我们在用户上传完文件后，立刻触发训练或者预测功能执行。

我们仔细看一下整体数据流图：“上传文件”是一个动作（或者可执行程序），文件存储到“（股票）数据存储”单元后，如何触发“训练”和“预测”的动作发生呢？

激活一个程序，有四种方式：

1. 人工手动启动程序
  
   不适合本场景，因为客户是在周末非工作时段上传文件的，工程师不一定保证能及时响应；而且我们也不能让客户来启动训练和预测过程，那样做风险太大。

2. 定时启动

   不适合本场景，因为不知道用户何时上传数据，如果正上传一半时启动程序，数据不完整，程序就会出错。无论怎样设置定时器，都有可能发生这种情况。

3. 由特殊事件触发
   
   使用块存储时，每次的文件上次都可以触发一次事件。我们是否可以监听这个事件作为触发机制呢？

   对于股票交易来说，如果上周有5个交易日，一共5个文件；如果只有3个交易日，就只有3个文件。所以用户每次上传一个文件，都会触发一次独立的文件变化通知，那么我们如何知道哪个通知是最后一个呢？也许用户上传了3个文件，喝了杯咖啡，然后又上传了2个文件。

   当时木头在做这个设计时，在小组内讨论了多次，其中一个 Dev Lead 认为我们应该在服务器端维护一套完美的逻辑，能够判断出“用户上传文件是否结束了”。但是，木头想来想去都觉得这是不可能完成的任务，总会有意外发生，不可能完美。

   还有一种设计：
   - 在客户端把所有要上传的文件先打包压缩成一个文件，然后把压缩文件上传，这样就只触发一次通知事件。但是这需要在客户端有“压缩”的逻辑代码，或者用一个第三方软件来完成。
   - 传到 Blob 上以后，在使用前需要先解压，在服务器端需要用同样的软件/协议来解压，然后再写回 Blob 中，便于以后使用。

   从逻辑上看，复杂很多，遂放弃。

4. 其它程序调用

   由于 Azure 边界的存在，上传文件行为是在客户端发生的，远在 Azure 之外，它不可能“调用”部署在 Azure 内的“训练”和“预测”模块，它只能“通知”。那么就需要我们再编制一个主控程序来接收“通知”，这样会多出一些工作来，但目前看来，这是我们唯一的解决方案。
   
   考虑到“训练”和“预测”模块的独立性，我们尽量不要改它们的业务逻辑，而是在外面单独增加一个控制中心，来接收来自客户端的“通知”，再做后续处理。即，在用户上传完文件后，由客户端手动或自动发送一个通知给控制中心，以便触发后面的工作流程。“上传”和“通知”两个动作最好在一个事务中完成。




<div align="center">
<img src="Images/Slide5.JPG"/>
图 10.3.3 - 设计触发机制
</div>

图 10.3.3 描述了上面所述的分析，我们统一称之为“通知机制”，即，如何通知一个程序启动。其中的1和4，表示在上传文件结束时，通知训练或者预测启动；2和3，表示被文件存储系统的变化事件激活；5表示在预测完毕后，如何通知用户下载文件。


<div align="center">
<img src="Images/Slide6.JPG"/>
图 10.3.3 - 设计触发机制
</div>



如图 10.3.1 所示的流程：
1. 上传文件结束后通知“控制中心”，这也避免了客户端程序直接接触到系统的核心功能，需要的话，在控制中心可以做各种保护措施；
2. 控制中心调度，执行训练；
3. 训练完毕后确定是否启用最新模型，然后执行预测，如果新模型性能不如旧模型，则依然使用旧模型预测；
4. 预测结束后通知用户去下载结果文件。

这种中心化的设计在系统设计中是很常见的。其缺点是要多设计、编码、部署出一个控制中心来，优点是业务逻辑非常容易调整，利大于弊。

## 10.2.8 控制门户的技术选择

首先要确定软件开发环境。因为训练、预测、模型管理都使用了 Python，所以我们干脆也用 Python 来实现控制门户吧，代码管理方便，部署环境一致，技术栈统一。

在 Python 中有很多 RESTful Web 框架，如 Django REST framework，Flask-RESTful 等等。

- Django REST framework 是一个功能强大且灵活的 REST Web API 框架，包含 OAuth1a、OAuth2身份验证策略，支持 ORM 和非 ORM 数据源的序列化，使用基于函数的常规视图实现自定义你所需要的功能，有广泛的文档资料和社区支持。

- Tornado是一种 Web 服务器软件的开源版本。Tornado 和现在的主流 Web 服务器框架（包括大多数 Python 的框架）有着明显的区别：它是非阻塞式服务器，而且速度相当快。得利于其非阻塞的方式和对epoll的运用，Tornado 每秒可以处理数以千计的连接，因此 Tornado 是实时 Web 服务的一个理想框架。

- Flask 是一个使用 Python 编写的轻量级 Web 应用框架。其 WSGI 工具箱采用 Werkzeug ，模板引擎则使用 Jinja2 。Flask也被称为 “microframework” ，因为它使用简单的核心，用 extension 增加其他功能。Flask没有默认使用的数据库、窗体验证工具。Flask 很轻，花很少的成本就能够开发一个简单的网站。非常适合初学者学习。Flask 框架学会以后，可以考虑学习插件的使用。例如使用 WTForm + Flask-WTForm 来验证表单数据，用 SQLAlchemy + Flask-SQLAlchemy 来对你的数据库进行控制。

还有4、5个其它的框架，都有很多拥趸。对于我们这个系统，用户很少，所以对性能没什么要求，只要开发简单、能够稳定运行即可。所以最后木头选择了 Flask API，只用十几行代码就可以搞定框架部分，每个 API 定义一个函数，指定好传入的参数，非常的方便，调试也很简单。



服务器端要不要做网页？

那么何时选择在服务器端处理类似逻辑呢？

当客户端有很多用户时，并且业务逻辑不那么复杂时，就可以考虑在服务器端写逻辑了。

针对这个问题，木头曾经和一个学生有过一番长达一个小时的讨论。。。。。。